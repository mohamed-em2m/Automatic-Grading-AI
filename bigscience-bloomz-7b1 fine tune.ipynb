{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7462033,"sourceType":"datasetVersion","datasetId":4088756},{"sourceId":7473637,"sourceType":"datasetVersion","datasetId":4345950},{"sourceId":7479009,"sourceType":"datasetVersion","datasetId":4353402}],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os","metadata":{"papermill":{"duration":0.73626,"end_time":"2023-10-28T13:41:22.664288","exception":false,"start_time":"2023-10-28T13:41:21.928028","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-25T13:00:48.287076Z","iopub.execute_input":"2024-01-25T13:00:48.287361Z","iopub.status.idle":"2024-01-25T13:00:48.895331Z","shell.execute_reply.started":"2024-01-25T13:00:48.287336Z","shell.execute_reply":"2024-01-25T13:00:48.894335Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install -U transformers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2  trl==0.4.7","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -U accelerate peft bitsandbytes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    TrainingArguments,\n    pipeline,\n    logging,\n    Trainer\n)\nfrom peft import LoraConfig, PeftModel\nfrom trl import SFTTrainer","metadata":{"papermill":{"duration":30.087603,"end_time":"2023-10-28T13:43:59.99579","exception":false,"start_time":"2023-10-28T13:43:29.908187","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-25T13:00:48.900644Z","iopub.execute_input":"2024-01-25T13:00:48.901312Z","iopub.status.idle":"2024-01-25T13:01:00.123760Z","shell.execute_reply.started":"2024-01-25T13:00:48.901273Z","shell.execute_reply":"2024-01-25T13:01:00.122820Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"# The model that you want to train from the Hugging Face hub\nmodel_name =\"bigscience/bloomz-7b1\"\n\n# The instruction dataset to use\n\n# Fine-tuned model name\nnew_model = \"bigscience/bloomz-7b1\"\n# LoRA attention dimension\nlora_r = 16\nlora_alpha = 16\n\n# Dropout probability for LoRA layers\nlora_dropout = 0.05\nuse_4bit = True\n\n# Compute dtype for 4-bit base models\nbnb_4bit_compute_dtype = \"float16\"\n\n# Quantization type (fp4 or nf4)\nbnb_4bit_quant_type = \"nf4\"\n\nuse_nested_quant = False\n\noutput_dir = \"./results\"\n\n# Number of training epochs\nnum_train_epochs = 1\nfp16 = False\nbf16 = False\n\nper_device_train_batch_size =1\n\nper_device_eval_batch_size = 4\n\ngradient_accumulation_steps = 8\n\ngradient_checkpointing = True\n\nmax_grad_norm = 0.3\n\nlearning_rate = 5e-5\n\nweight_decay = 0.001\n\noptim = \"paged_adamw_8bit\"\n\nlr_scheduler_type = \"constant\"\n\nmax_steps = -1\nwarmup_ratio = 0.03\ngroup_by_length = True\n\nsave_steps = 100\n\nlogging_steps = 25\n\nmax_seq_length = False\npacking = False\n#device_map = {\"\": 0}","metadata":{"execution":{"iopub.status.busy":"2024-01-25T13:01:00.124980Z","iopub.execute_input":"2024-01-25T13:01:00.125796Z","iopub.status.idle":"2024-01-25T13:01:00.133582Z","shell.execute_reply.started":"2024-01-25T13:01:00.125765Z","shell.execute_reply":"2024-01-25T13:01:00.132542Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-25T13:01:00.136162Z","iopub.execute_input":"2024-01-25T13:01:00.136660Z","iopub.status.idle":"2024-01-25T13:01:01.267685Z","shell.execute_reply.started":"2024-01-25T13:01:00.136632Z","shell.execute_reply":"2024-01-25T13:01:01.266802Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Load dataset (you can process it here)\n\n# Load tokenizer and model with QLoRA configuration\ncompute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=use_4bit,\n    bnb_4bit_quant_type=bnb_4bit_quant_type,\n    bnb_4bit_compute_dtype=compute_dtype,\n    bnb_4bit_use_double_quant=use_nested_quant,\n)\n\n# Check GPU compatibility with bfloat16\nif compute_dtype == torch.float16 and use_4bit:\n    major, _ = torch.cuda.get_device_capability()\n    if major >= 8:\n        print(\"=\" * 80)\n        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n        print(\"=\" * 80)\n\n# Load base model\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    quantization_config=bnb_config,\n)\nmodel.config.use_cache = False\nmodel.config.pretraining_tp = 1\n\n# Load LLaMA tokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"right\"\npeft_config = LoraConfig(\n    lora_alpha=lora_alpha,\n    lora_dropout=lora_dropout,\n    r=lora_r,\n    target_modules=['query_key_value', 'dense_h_to_4h', 'dense_4h_to_h', 'dense'],\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-25T13:01:01.268996Z","iopub.execute_input":"2024-01-25T13:01:01.269383Z","iopub.status.idle":"2024-01-25T13:03:22.629525Z","shell.execute_reply.started":"2024-01-25T13:01:01.269339Z","shell.execute_reply":"2024-01-25T13:03:22.628380Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"}]},{"cell_type":"code","source":"model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-25T13:03:22.631746Z","iopub.execute_input":"2024-01-25T13:03:22.632089Z","iopub.status.idle":"2024-01-25T13:03:23.711916Z","shell.execute_reply.started":"2024-01-25T13:03:22.632059Z","shell.execute_reply":"2024-01-25T13:03:23.711052Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"!pip install -q datasets trl peft bitsandbytes sentencepiece wandb","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ntrain_df = pd.read_csv(\"/kaggle/input/expect-answer-true-or-false-arabic/data.csv\").iloc[:-5000]\nvalid_df = pd.read_csv(\"/kaggle/input/expect-answer-true-or-false-arabic/data.csv\").iloc[-5000:]\ntest_df = pd.read_csv(\"/kaggle/input/expect-answer-true-or-false-arabic/data.csv\").iloc[-5000:]","metadata":{"id":"M9nKf_Rq_DmB","papermill":{"duration":7.182899,"end_time":"2023-10-28T13:44:19.463101","exception":false,"start_time":"2023-10-28T13:44:12.280202","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def chat_Format(context,answer):\n   return \"Instruction:\\ncheck answer is true or false of next quetion using context below:\\n\"+context+ f\".\\n#Student answer: \"+answer+\".\\n#Response:\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['input']=chat_Format(train_df['question'],train_df['answer'] )+train_df['label']\nvalid_df['input']=chat_Format(valid_df['question'],valid_df['answer'] ) +valid_df['label']\nvalid_df['input2']=chat_Format(valid_df['question'],valid_df['answer'] )","metadata":{"papermill":{"duration":1.076472,"end_time":"2023-10-28T13:44:20.560638","exception":false,"start_time":"2023-10-28T13:44:19.484166","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['input']=train_df['input'].apply(lambda x:x.replace('CANNOTANSWER',''))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_df['input2']=valid_df['input2'].apply(lambda x:x.replace('CANNOTANSWER',''))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"m=-12\nw=np.zeros(len(train_df))\no=0\nfor i in train_df['input']:\n    t=len(tokenizer(i)['input_ids'])\n    w[o]=t\n    o+=1\n    print(o,end='\\r')\nm=-12\na=np.zeros(len(valid_df))\no=0\nfor i in valid_df['input']:\n    t=len(tokenizer(i)['input_ids'])\n    a[o]=t\n    o+=1    \n    print(o,end='\\r')\n\ntrain_df=train_df.loc[w<650]\nvalid_df=valid_df.loc[a<650]   \ntrain_texts=train_df\nvalid_texts=valid_df\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/bloomz-arabi-proote/train.csv\")\nvalid_df = pd.read_csv(\"/kaggle/input/bloomz-arabi-proote/valid.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-01-25T13:03:23.714155Z","iopub.execute_input":"2024-01-25T13:03:23.714705Z","iopub.status.idle":"2024-01-25T13:03:34.165285Z","shell.execute_reply.started":"2024-01-25T13:03:23.714662Z","shell.execute_reply":"2024-01-25T13:03:34.164449Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Datasets and Dataloaders\nfrom torch.utils.data import Dataset, DataLoader\n\nclass QADataset(Dataset):\n    def __init__(self, encodings):\n        self.inputs = encodings['input']\n        \n    def __getitem__(self, idx):\n        a=tokenizer(self.inputs[idx] , truncation=True, padding='max_length', return_tensors=\"pt\", max_length=650)\n        return {\n            \n            \"input_ids\": a[\"input_ids\"][0],\n            \"attention_mask\": a[\"attention_mask\"][0],\n            \"labels\":a['input_ids'][0]\n        }\n    def __len__(self):\n        return len(self.inputs)\ntrain_dataset = QADataset(train_df.iloc[28000:37000].reset_index(drop=True))\nval_dataset = QADataset(valid_df.iloc[:100].reset_index(drop=True))\n","metadata":{"id":"zZydmxRxKK6j","outputId":"d26160fb-59ed-4e0e-fb2e-0d2f3546743c","papermill":{"duration":0.035718,"end_time":"2023-10-28T13:44:24.58275","exception":false,"start_time":"2023-10-28T13:44:24.547032","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n!pip install wandb\nimport wandb\nwandb.login(key=\"14459c516497ab76a78f7fc1278bfe60d301d250\")","metadata":{"papermill":{"duration":14.026469,"end_time":"2023-10-28T13:44:38.629031","exception":false,"start_time":"2023-10-28T13:44:24.602562","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.to_csv('train.csv')\nvalid_df.to_csv('valid.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"peftmodel=PeftModel.from_pretrained(model,\"/kaggle/input/proote/results/checkpoint-1000\",is_trainable=True)\npeftmodel.enable_input_require_grads()\npeftmodel.train()","metadata":{"execution":{"iopub.status.busy":"2024-01-25T13:03:34.169419Z","iopub.execute_input":"2024-01-25T13:03:34.169728Z","iopub.status.idle":"2024-01-25T13:03:36.010081Z","shell.execute_reply.started":"2024-01-25T13:03:34.169700Z","shell.execute_reply":"2024-01-25T13:03:36.009144Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): BloomForCausalLM(\n      (transformer): BloomModel(\n        (word_embeddings): Embedding(250880, 4096)\n        (word_embeddings_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (h): ModuleList(\n          (0-29): 30 x BloomBlock(\n            (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n            (self_attention): BloomAttention(\n              (query_key_value): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=12288, bias=True)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=12288, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (dense): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=True)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (attention_dropout): Dropout(p=0.0, inplace=False)\n            )\n            (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n            (mlp): BloomMLP(\n              (dense_h_to_4h): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=16384, bias=True)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=16384, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (gelu_impl): BloomGelu()\n              (dense_4h_to_h): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=16384, out_features=4096, bias=True)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=16384, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n            )\n          )\n        )\n        (ln_f): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n      )\n      (lm_head): Linear(in_features=4096, out_features=250880, bias=False)\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_arguments = TrainingArguments(\n    output_dir=output_dir,\n    num_train_epochs=num_train_epochs,\n    per_device_train_batch_size=3,\n    gradient_accumulation_steps=3,\n    optim=optim,\n    save_steps=200,\n    logging_steps=15,\n    learning_rate=learning_rate,\n    weight_decay=weight_decay,\n    fp16=fp16, \n    bf16=bf16,\n    max_grad_norm=max_grad_norm,\n    max_steps=max_steps,\n    warmup_ratio=warmup_ratio,\n    group_by_length=False,\n    lr_scheduler_type=lr_scheduler_type,\n   gradient_checkpointing=gradient_checkpointing\n)\n\ntrainer = SFTTrainer(\n    model=peftmodel,\n    train_dataset=train_dataset,\n        eval_dataset=val_dataset,\n\n    peft_config=None,\n    dataset_text_field=\"text\",\n    args=training_arguments,\n    packing=False,\n)\ntrainer.train()\ntrainer.model.save_pretrained(new_model)","metadata":{"id":"yqq_9dT1_nn7","papermill":{"duration":8.04449,"end_time":"2023-10-28T13:44:46.754051","exception":false,"start_time":"2023-10-28T13:44:38.709561","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#peftmodel.save_pretrained(\"bloom\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.evaluate()\n","metadata":{"papermill":{"duration":699.247728,"end_time":"2023-10-28T19:40:46.786544","exception":false,"start_time":"2023-10-28T19:29:07.538816","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install evaluate","metadata":{"papermill":{"duration":12.363574,"end_time":"2023-10-28T19:40:59.174346","exception":false,"start_time":"2023-10-28T19:40:46.810772","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install rouge_score","metadata":{"papermill":{"duration":13.908888,"end_time":"2023-10-28T19:41:13.11008","exception":false,"start_time":"2023-10-28T19:40:59.201192","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#peftmodel=PeftModel.from_pretrained(model,\"/kaggle/input/bloomz-arabi-proote/results/checkpoint-1000\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\ntokenizer.padding_side = \"left\"","metadata":{"execution":{"iopub.status.busy":"2024-01-25T13:03:36.011416Z","iopub.execute_input":"2024-01-25T13:03:36.011794Z","iopub.status.idle":"2024-01-25T13:03:36.016718Z","shell.execute_reply.started":"2024-01-25T13:03:36.011758Z","shell.execute_reply":"2024-01-25T13:03:36.015790Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"peftmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2024-01-25T13:03:36.017922Z","iopub.execute_input":"2024-01-25T13:03:36.018209Z","iopub.status.idle":"2024-01-25T13:03:36.049890Z","shell.execute_reply.started":"2024-01-25T13:03:36.018183Z","shell.execute_reply":"2024-01-25T13:03:36.048878Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): BloomForCausalLM(\n      (transformer): BloomModel(\n        (word_embeddings): Embedding(250880, 4096)\n        (word_embeddings_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (h): ModuleList(\n          (0-29): 30 x BloomBlock(\n            (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n            (self_attention): BloomAttention(\n              (query_key_value): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=12288, bias=True)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=12288, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (dense): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=True)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (attention_dropout): Dropout(p=0.0, inplace=False)\n            )\n            (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n            (mlp): BloomMLP(\n              (dense_h_to_4h): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=16384, bias=True)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=16384, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (gelu_impl): BloomGelu()\n              (dense_4h_to_h): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=16384, out_features=4096, bias=True)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=16384, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n            )\n          )\n        )\n        (ln_f): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n      )\n      (lm_head): Linear(in_features=4096, out_features=250880, bias=False)\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import logging\n\n# Disable transformers library warnings\nlogging.set_verbosity_error()\n#import evaluate\nimport numpy as np\nfrom datasets import load_from_disk\nfrom tqdm import tqdm\n\n# Metric\n#metric= evaluate.load(\"rouge\")\n#metric2= evaluate.load(\"bleu\")\n\npredictions, references = [] , []\no=0\ns=0\nl=1000\nstep=4\nfor i in range(0,l,step):\n        inp2=valid_df['input2'].iloc[i:i+step]\n\n        w=tokenizer(inp2.tolist(), add_special_tokens=True,\n            pad_to_max_length=True,\n            return_attention_mask=True,\n            return_tensors='pt',    max_length=650\n\n        )\n        d=tokenizer.batch_decode(peftmodel.generate(input_ids=w['input_ids'].cuda(),attention_mask=w['attention_mask'].cuda(),num_beams=2,max_new_tokens=3),skip_special_tokens=True)\n        for o in range(len(d)):  \n\n            e=d[o][d[o].find(f'\\n#Response:')+len(f'\\n#Response:'):]     \n            c=(e+' ,').split()[0].strip().lower().strip(':').strip('.')\n            if(c=='\\ntrue'):\n                c='true'\n            elif(c=='خط'):\n                c='خطأ'\n            a=valid_df['label'].iloc[i+o].split()[0]\n            s+=int((e+' ,').split()[0].strip().lower()==valid_df['label'].iloc[i+o].split()[0].strip().lower())\n            print(f'{i} : {s/(i+o+1)} ',end='\\r')\n            predictions+=[c]\n            references+=[valid_df['label'].iloc[i+o]]\n","metadata":{"papermill":{"duration":3016.084022,"end_time":"2023-10-28T20:31:29.221828","exception":true,"start_time":"2023-10-28T19:41:13.137806","status":"failed"},"tags":[],"execution":{"iopub.status.busy":"2024-01-25T13:23:45.672063Z","iopub.execute_input":"2024-01-25T13:23:45.672503Z","iopub.status.idle":"2024-01-25T13:23:57.651314Z","shell.execute_reply.started":"2024-01-25T13:23:45.672468Z","shell.execute_reply":"2024-01-25T13:23:57.649930Z"},"trusted":true},"execution_count":33,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[33], line 28\u001b[0m\n\u001b[1;32m     20\u001b[0m inp2\u001b[38;5;241m=\u001b[39mvalid_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput2\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[i:i\u001b[38;5;241m+\u001b[39mstep]\n\u001b[1;32m     22\u001b[0m w\u001b[38;5;241m=\u001b[39mtokenizer(inp2\u001b[38;5;241m.\u001b[39mtolist(), add_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     23\u001b[0m     pad_to_max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     24\u001b[0m     return_attention_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     25\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m,    max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m650\u001b[39m\n\u001b[1;32m     26\u001b[0m \n\u001b[1;32m     27\u001b[0m )\n\u001b[0;32m---> 28\u001b[0m d\u001b[38;5;241m=\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(\u001b[43mpeftmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m,skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(d)):  \n\u001b[1;32m     31\u001b[0m     e\u001b[38;5;241m=\u001b[39md[o][d[o]\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m#Response:\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m#Response:\u001b[39m\u001b[38;5;124m'\u001b[39m):]     \n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/peft/peft_model.py:1130\u001b[0m, in \u001b[0;36mPeftModelForCausalLM.generate\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model\u001b[38;5;241m.\u001b[39mgeneration_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_config\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model_prepare_inputs_for_generation\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1558\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1552\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1553\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   1554\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1555\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1556\u001b[0m     )\n\u001b[1;32m   1557\u001b[0m     \u001b[38;5;66;03m# 13. run beam search\u001b[39;00m\n\u001b[0;32m-> 1558\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeam_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeam_scorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1561\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1562\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1565\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1566\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1567\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1568\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE:\n\u001b[1;32m   1572\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   1573\u001b[0m     logits_warper \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:2995\u001b[0m, in \u001b[0;36mGenerationMixin.beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   2992\u001b[0m next_tokens \u001b[38;5;241m=\u001b[39m next_tokens \u001b[38;5;241m%\u001b[39m vocab_size\n\u001b[1;32m   2994\u001b[0m \u001b[38;5;66;03m# stateless\u001b[39;00m\n\u001b[0;32m-> 2995\u001b[0m beam_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mbeam_scorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2996\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2997\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnext_token_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnext_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2999\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnext_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3000\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3001\u001b[0m \u001b[43m    \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3002\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeam_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeam_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3003\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_prompt_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_prompt_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3004\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3006\u001b[0m beam_scores \u001b[38;5;241m=\u001b[39m beam_outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext_beam_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   3007\u001b[0m beam_next_tokens \u001b[38;5;241m=\u001b[39m beam_outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext_beam_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/beam_search.py:253\u001b[0m, in \u001b[0;36mBeamSearchScorer.process\u001b[0;34m(self, input_ids, next_scores, next_tokens, next_indices, pad_token_id, eos_token_id, beam_indices, group_index, decoder_prompt_len)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_size):\n\u001b[1;32m    252\u001b[0m     batch_group_idx \u001b[38;5;241m=\u001b[39m batch_idx \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_beam_groups \u001b[38;5;241m+\u001b[39m group_index\n\u001b[0;32m--> 253\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_done[batch_group_idx]:\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_beams \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_beam_hyps[batch_group_idx]):\n\u001b[1;32m    255\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch can only be done if at least \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_beams\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m beams have been generated\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"references","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"accuracy : {s/(i+1)}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"peft_model_id=\"results\"\ntrainer.model.save_pretrained(peft_model_id)\ntokenizer.save_pretrained(peft_model_id)","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"context =\"\"\"تقنية النانو أحد األساليب المبتكرة لدراسة المادة وطرق تغييرها عند مستوى النانو؛ من أجل إنتاج\nًّ مواد أخرى متطورة تخدم البشرية فى مختلف مجاالت الحياة، والنانو وحدة قياس دقيقة جدا ؛ فالنانو الواحد\nيعادل واحدا على المليون من المليمتر ؛ لذلك تستحيل رؤية األشياء المقاسة بالنانو بواسطة العين المجردة،\nأو حتى بمكبرات الرؤية البدائية، وهى تستخدم فى القياس الذرى لتحديد األحجام الخاصة بجزئيات المادة\nالمتواجدة بها.\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-01-25T13:14:45.865722Z","iopub.execute_input":"2024-01-25T13:14:45.866133Z","iopub.status.idle":"2024-01-25T13:14:45.873371Z","shell.execute_reply.started":"2024-01-25T13:14:45.866098Z","shell.execute_reply":"2024-01-25T13:14:45.872512Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"quetion=\" لماذا لا يمكن رؤية النانو؟\"","metadata":{"execution":{"iopub.status.busy":"2024-01-25T13:14:46.052589Z","iopub.execute_input":"2024-01-25T13:14:46.052963Z","iopub.status.idle":"2024-01-25T13:14:46.058109Z","shell.execute_reply.started":"2024-01-25T13:14:46.052937Z","shell.execute_reply":"2024-01-25T13:14:46.056938Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"answer=\"لانها  شديدة كبيرة جدا\"","metadata":{"execution":{"iopub.status.busy":"2024-01-25T13:14:46.256033Z","iopub.execute_input":"2024-01-25T13:14:46.256441Z","iopub.status.idle":"2024-01-25T13:14:46.261146Z","shell.execute_reply.started":"2024-01-25T13:14:46.256398Z","shell.execute_reply":"2024-01-25T13:14:46.260063Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig,HfArgumentParser,TrainingArguments,pipeline, logging, TextStreamer\n","metadata":{"execution":{"iopub.status.busy":"2024-01-25T13:14:46.421764Z","iopub.execute_input":"2024-01-25T13:14:46.422163Z","iopub.status.idle":"2024-01-25T13:14:46.429673Z","shell.execute_reply.started":"2024-01-25T13:14:46.422129Z","shell.execute_reply":"2024-01-25T13:14:46.428715Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"peftmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2024-01-25T13:14:46.639951Z","iopub.execute_input":"2024-01-25T13:14:46.640646Z","iopub.status.idle":"2024-01-25T13:14:46.667395Z","shell.execute_reply.started":"2024-01-25T13:14:46.640609Z","shell.execute_reply":"2024-01-25T13:14:46.666389Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): BloomForCausalLM(\n      (transformer): BloomModel(\n        (word_embeddings): Embedding(250880, 4096)\n        (word_embeddings_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (h): ModuleList(\n          (0-29): 30 x BloomBlock(\n            (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n            (self_attention): BloomAttention(\n              (query_key_value): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=12288, bias=True)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=12288, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (dense): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=True)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (attention_dropout): Dropout(p=0.0, inplace=False)\n            )\n            (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n            (mlp): BloomMLP(\n              (dense_h_to_4h): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=16384, bias=True)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=16384, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (gelu_impl): BloomGelu()\n              (dense_4h_to_h): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=16384, out_features=4096, bias=True)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=16384, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n            )\n          )\n        )\n        (ln_f): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n      )\n      (lm_head): Linear(in_features=4096, out_features=250880, bias=False)\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"def chat_Format(context,question,answer):\n   return \"Instruction:\\ncheck answer is true or false of next quetion using context below:\\nContext \"+context+\"\\nQuestion \"+question + f\".\\n#Student answer: \"+answer+\".\\n#Response:\"","metadata":{"execution":{"iopub.status.busy":"2024-01-25T13:14:46.825267Z","iopub.execute_input":"2024-01-25T13:14:46.826246Z","iopub.status.idle":"2024-01-25T13:14:46.830667Z","shell.execute_reply.started":"2024-01-25T13:14:46.826209Z","shell.execute_reply":"2024-01-25T13:14:46.829675Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"        inp2=chat_Format(context,quetion,answer)\n        streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n\n        w=tokenizer(inp2, add_special_tokens=True,\n            pad_to_max_length=True,\n            return_attention_mask=True,\n            return_tensors='pt'\n\n        )\n        for i in tokenizer.batch_decode(model.generate(input_ids=w['input_ids'].cuda(),attention_mask=w['attention_mask'].cuda(),num_beams=7,num_return_sequences=2,max_new_tokens=60 ),skip_special_tokens=True):\n                print(i)","metadata":{"execution":{"iopub.status.busy":"2024-01-25T13:35:22.750772Z","iopub.execute_input":"2024-01-25T13:35:22.751592Z","iopub.status.idle":"2024-01-25T13:35:40.068933Z","shell.execute_reply.started":"2024-01-25T13:35:22.751554Z","shell.execute_reply":"2024-01-25T13:35:40.067859Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Instruction:\ncheck answer is true or false of next quetion using context below:\nContext تقنية النانو أحد األساليب المبتكرة لدراسة المادة وطرق تغييرها عند مستوى النانو؛ من أجل إنتاج\nًّ مواد أخرى متطورة تخدم البشرية فى مختلف مجاالت الحياة، والنانو وحدة قياس دقيقة جدا ؛ فالنانو الواحد\nيعادل واحدا على المليون من المليمتر ؛ لذلك تستحيل رؤية األشياء المقاسة بالنانو بواسطة العين المجردة،\nأو حتى بمكبرات الرؤية البدائية، وهى تستخدم فى القياس الذرى لتحديد األحجام الخاصة بجزئيات المادة\nالمتواجدة بها.\nQuestion  لماذا لا يمكن رؤية النانو؟.\n#Student answer: لانها  شديدة كبيرة جدا.\n#Response:خطأ الجواب هو لا يمكن رؤية النانو بواسطة العين المجردة ، أو حتى بمكبرات الرؤية البدائية.وذلك لأن النانو واحد يعادل واحد على المليون من المليمتر.لذلك ، لا يمكن رؤية النانو بواسطة العين المجردة ، أو حتى بمكبرات الرؤية البدائية ، لأنها\nInstruction:\ncheck answer is true or false of next quetion using context below:\nContext تقنية النانو أحد األساليب المبتكرة لدراسة المادة وطرق تغييرها عند مستوى النانو؛ من أجل إنتاج\nًّ مواد أخرى متطورة تخدم البشرية فى مختلف مجاالت الحياة، والنانو وحدة قياس دقيقة جدا ؛ فالنانو الواحد\nيعادل واحدا على المليون من المليمتر ؛ لذلك تستحيل رؤية األشياء المقاسة بالنانو بواسطة العين المجردة،\nأو حتى بمكبرات الرؤية البدائية، وهى تستخدم فى القياس الذرى لتحديد األحجام الخاصة بجزئيات المادة\nالمتواجدة بها.\nQuestion  لماذا لا يمكن رؤية النانو؟.\n#Student answer: لانها  شديدة كبيرة جدا.\n#Response:خطأ الجواب هو لا يمكن رؤية النانو بواسطة العين المجردة ، أو حتى بمكبرات الرؤية البدائية.وذلك لأن النانو واحد يعادل واحد على المليون من المليمتر.لذلك ، لا يمكن رؤية النانو بواسطة العين المجردة ، أو حتى بمكبرات الرؤية البدائية.هذا\n","output_type":"stream"}]},{"cell_type":"code","source":"s=peftmodel( input_ids=w['input_ids'].cuda(),attention_mask=w['attention_mask'].cuda())['logits'][0][-1]","metadata":{"execution":{"iopub.status.busy":"2024-01-25T13:15:00.243135Z","iopub.execute_input":"2024-01-25T13:15:00.243654Z","iopub.status.idle":"2024-01-25T13:15:00.482250Z","shell.execute_reply.started":"2024-01-25T13:15:00.243612Z","shell.execute_reply":"2024-01-25T13:15:00.481381Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"e=(s/s.sum())\n(s[16068]/(s[170089]+s[16068]))**.5","metadata":{"execution":{"iopub.status.busy":"2024-01-25T13:15:30.387062Z","iopub.execute_input":"2024-01-25T13:15:30.388033Z","iopub.status.idle":"2024-01-25T13:15:30.396686Z","shell.execute_reply.started":"2024-01-25T13:15:30.387999Z","shell.execute_reply":"2024-01-25T13:15:30.395661Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"tensor(0.7065, device='cuda:0', dtype=torch.float16, grad_fn=<PowBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"s.argmax()","metadata":{"execution":{"iopub.status.busy":"2024-01-25T13:15:30.620728Z","iopub.execute_input":"2024-01-25T13:15:30.621802Z","iopub.status.idle":"2024-01-25T13:15:30.641120Z","shell.execute_reply.started":"2024-01-25T13:15:30.621752Z","shell.execute_reply":"2024-01-25T13:15:30.640241Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"tensor(170089, device='cuda:0')"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.batch_decode([16068])","metadata":{"execution":{"iopub.status.busy":"2024-01-25T13:15:14.972597Z","iopub.execute_input":"2024-01-25T13:15:14.973680Z","iopub.status.idle":"2024-01-25T13:15:14.979838Z","shell.execute_reply.started":"2024-01-25T13:15:14.973640Z","shell.execute_reply":"2024-01-25T13:15:14.978879Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"['خط']"},"metadata":{}}]},{"cell_type":"code","source":"model.generate(input_ids=w['input_ids'].cuda(),attention_mask=w['attention_mask'].cuda(),streamer=streamer,max_new_tokens=30 )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
