{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7340328,"sourceType":"datasetVersion","datasetId":3869148},{"sourceId":7437439,"sourceType":"datasetVersion","datasetId":4327947},{"sourceId":7442484,"sourceType":"datasetVersion","datasetId":4331898},{"sourceId":7491824,"sourceType":"datasetVersion","datasetId":4329071},{"sourceId":8563896,"sourceType":"datasetVersion","datasetId":5066615},{"sourceId":8724101,"sourceType":"datasetVersion","datasetId":5235446},{"sourceId":8726721,"sourceType":"datasetVersion","datasetId":5237323}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os","metadata":{"papermill":{"duration":0.73626,"end_time":"2023-10-28T13:41:22.664288","exception":false,"start_time":"2023-10-28T13:41:21.928028","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-20T17:43:43.687773Z","iopub.execute_input":"2024-06-20T17:43:43.688514Z","iopub.status.idle":"2024-06-20T17:43:44.215339Z","shell.execute_reply.started":"2024-06-20T17:43:43.688460Z","shell.execute_reply":"2024-06-20T17:43:44.214416Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2  trl==0.4.7","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -U transformers trl","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q accelerate peft==0.4.0 bitsandbytes==0.40.2  trl","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -U accelerate peft bitsandbytes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q accelerate peft","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,AutoModel,\n    TrainingArguments,\n    pipeline,\n    Trainer\n)\nfrom peft import LoraConfig, PeftModel,get_peft_config,get_peft_model\nfrom trl import SFTTrainer","metadata":{"papermill":{"duration":30.087603,"end_time":"2023-10-28T13:43:59.99579","exception":false,"start_time":"2023-10-28T13:43:29.908187","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-20T17:43:46.930315Z","iopub.execute_input":"2024-06-20T17:43:46.931334Z","iopub.status.idle":"2024-06-20T17:43:56.794673Z","shell.execute_reply.started":"2024-06-20T17:43:46.931297Z","shell.execute_reply":"2024-06-20T17:43:56.793740Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2024-06-20 17:43:51.282371: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-20 17:43:51.282439: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-20 17:43:51.284099: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The model that you want to train from the Hugging Face hub\nmodel_name =\"llava-hf/llava-1.5-7b-hf\"\n\n# The instruction dataset to use\n\n# Fine-tuned model name\nnew_model = \"llava-hf/llava-1.5-7b-hf\"\n# LoRA attention dimension\nlora_r = 16\nlora_alpha = 16\n\n# Dropout probability for LoRA layers\nlora_dropout = 0.05\nuse_4bit = True\n\n# Compute dtype for 4-bit base models\nbnb_4bit_compute_dtype = \"float16\"\n\n# Quantization type (fp4 or nf4)\nbnb_4bit_quant_type = \"nf4\"\n\nuse_nested_quant = False\n\noutput_dir = \"./results\"\n\n# Number of training epochs\nnum_train_epochs = 1\nfp16 = False\nbf16 = False\n\nper_device_train_batch_size =1\n\nper_device_eval_batch_size = 4\n\ngradient_accumulation_steps = 8\n\ngradient_checkpointing = True\n\nmax_grad_norm = 0.3\n\nlearning_rate = 3e-5\n\nweight_decay = 0.001\n\noptim = \"paged_adamw_32bit\"\n\nlr_scheduler_type = \"constant\"\n\nmax_steps = -1\nwarmup_ratio = 0.03\ngroup_by_length = True\n\nsave_steps = 100\n\nlogging_steps = 25\n\nmax_seq_length = False\npacking = False\n#device_map = {\"\": 0}","metadata":{"execution":{"iopub.status.busy":"2024-06-20T17:44:16.746264Z","iopub.execute_input":"2024-06-20T17:44:16.747257Z","iopub.status.idle":"2024-06-20T17:44:16.755671Z","shell.execute_reply.started":"2024-06-20T17:44:16.747218Z","shell.execute_reply":"2024-06-20T17:44:16.754384Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoProcessor, AutoModelForPreTraining,LlavaForConditionalGeneration","metadata":{"execution":{"iopub.status.busy":"2024-06-20T17:44:18.382193Z","iopub.execute_input":"2024-06-20T17:44:18.382919Z","iopub.status.idle":"2024-06-20T17:44:18.389325Z","shell.execute_reply.started":"2024-06-20T17:44:18.382868Z","shell.execute_reply":"2024-06-20T17:44:18.388123Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Load dataset (you can process it here)\n\n# Load tokenizer and model with QLoRA configuration\ncompute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=use_4bit,\n    bnb_4bit_quant_type=bnb_4bit_quant_type,\n    bnb_4bit_compute_dtype=compute_dtype,\n    bnb_4bit_use_double_quant=use_nested_quant,\n)\n\n# Check GPU compatibility with bfloat16\nif compute_dtype == torch.float16 and use_4bit:\n    major, _ = torch.cuda.get_device_capability()\n    if major >= 8:\n        print(\"=\" * 80)\n        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n        print(\"=\" * 80)\n\n# Load base model\nmodel = LlavaForConditionalGeneration.from_pretrained(\n    model_name,\n    quantization_config=bnb_config\n)\n#model.config.use_cache = False\n#model.config.pretraining_tp = 1\n\n# Load LLaMA tokenizer\ntokenizer = AutoProcessor.from_pretrained(model_name)\ntokenizer.padding_side = \"right\"\npeft_config = LoraConfig(\n    lora_alpha=lora_alpha,\n    lora_dropout=lora_dropout,\n    r=lora_r,\n    target_modules=['k_proj', 'gate_proj', 'v_proj', 'up_proj', 'q_proj', 'o_proj', 'down_proj'],\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-20T17:44:24.562926Z","iopub.execute_input":"2024-06-20T17:44:24.563372Z","iopub.status.idle":"2024-06-20T17:45:32.255639Z","shell.execute_reply.started":"2024-06-20T17:44:24.563338Z","shell.execute_reply":"2024-06-20T17:45:32.254545Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/950 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c39e77424e1a450795ec0b7d3bfe21e5"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/llava/configuration_llava.py:100: FutureWarning: The `vocab_size` argument is deprecated and will be removed in v4.42, since it can be inferred from the `text_config`. Passing this argument has no effect\n  warnings.warn(\n`low_cpu_mem_usage` was None, now set to True since model is quantized.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/70.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11308ef302e84f8198a7ad91d22c859d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83d674b65ad242eb91bde509a8ff883b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b692ec438e2b49bfb66a4f73abc6e333"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d0b786cdcb345fbae6fe3e83f4c1e4a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/4.18G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a29f5f8b0e948f4ad15b0bfc813c1e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8be45daa16741eb9b46805c8eeb9a53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/141 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efe0517e44c542a7b67cb98722af95b4"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndata = pd.read_csv(\"/kaggle/input/false-true-images-for-minicpm/make-true-false-image-db/data.csv\")","metadata":{"id":"M9nKf_Rq_DmB","papermill":{"duration":7.182899,"end_time":"2023-10-28T13:44:19.463101","exception":false,"start_time":"2023-10-28T13:44:12.280202","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-20T17:54:28.094249Z","iopub.execute_input":"2024-06-20T17:54:28.094714Z","iopub.status.idle":"2024-06-20T17:54:28.109820Z","shell.execute_reply.started":"2024-06-20T17:54:28.094678Z","shell.execute_reply":"2024-06-20T17:54:28.108705Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"tokenizer.padding_side = \"right\"","metadata":{"execution":{"iopub.status.busy":"2024-06-20T17:54:28.337007Z","iopub.execute_input":"2024-06-20T17:54:28.338717Z","iopub.status.idle":"2024-06-20T17:54:28.344787Z","shell.execute_reply.started":"2024-06-20T17:54:28.338666Z","shell.execute_reply":"2024-06-20T17:54:28.343300Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"data=data.sample(len(data))","metadata":{"execution":{"iopub.status.busy":"2024-06-20T17:54:29.224216Z","iopub.execute_input":"2024-06-20T17:54:29.224977Z","iopub.status.idle":"2024-06-20T17:54:29.231159Z","shell.execute_reply.started":"2024-06-20T17:54:29.224939Z","shell.execute_reply":"2024-06-20T17:54:29.230032Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"from PIL import Image","metadata":{"execution":{"iopub.status.busy":"2024-06-20T17:46:26.672971Z","iopub.execute_input":"2024-06-20T17:46:26.673353Z","iopub.status.idle":"2024-06-20T17:46:26.677788Z","shell.execute_reply.started":"2024-06-20T17:46:26.673324Z","shell.execute_reply":"2024-06-20T17:46:26.676694Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Datasets and Dataloaders\nfrom torch.utils.data import Dataset, DataLoader\n\nclass QADataset(Dataset):\n    def __init__(self, encodings):\n        self.inputs = encodings\n        \n    def __getitem__(self, idx):\n        d=self.inputs.iloc[idx]\n        d=self.inputs.iloc[idx]\n        text=\"USER: <image>\\nanswer with true or false analysis the two images and determine if they the same or not? ASSISTANT:\"\n        labels=d['labels']\n        path=\"/kaggle/input/false-true-images-for-minicpm/make-true-false-image-db/train/\"+d['merged']\n        image=Image.open(path).resize((448,448))\n        with torch.set_grad_enabled(True):\n                preproces = tokenizer(text=text+str(d[-1]), images=image, return_tensors=\"pt\",truncation=True,)\n                for i in  preproces.keys():\n                   preproces[i]=preproces[i].squeeze(0).cuda()\n\n\n                  #  preproces[i].requie_gradient=True\n                return preproces\n    def __len__(self):\n        return len(self.inputs)\ntrain_dataset = QADataset(data.iloc[0:1400].reset_index(drop=True))\nval_dataset = QADataset(data.iloc[-100:].reset_index(drop=True))\n","metadata":{"id":"zZydmxRxKK6j","outputId":"d26160fb-59ed-4e0e-fb2e-0d2f3546743c","papermill":{"duration":0.035718,"end_time":"2023-10-28T13:44:24.58275","exception":false,"start_time":"2023-10-28T13:44:24.547032","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-20T18:00:13.321979Z","iopub.execute_input":"2024-06-20T18:00:13.322930Z","iopub.status.idle":"2024-06-20T18:00:13.335683Z","shell.execute_reply.started":"2024-06-20T18:00:13.322888Z","shell.execute_reply":"2024-06-20T18:00:13.334292Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"data[data['labels']==False]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nimport json","metadata":{"execution":{"iopub.status.busy":"2024-06-20T17:46:30.309781Z","iopub.execute_input":"2024-06-20T17:46:30.310450Z","iopub.status.idle":"2024-06-20T17:46:30.314798Z","shell.execute_reply.started":"2024-06-20T17:46:30.310412Z","shell.execute_reply":"2024-06-20T17:46:30.313694Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"combine=[]\nfor i in os.listdir(\"/kaggle/input/false-true-images-for-minicpm/make-true-false-image-db/train/train_json\"):\n    with open(\"/kaggle/input/false-true-images-for-minicpm/make-true-false-image-db/train/train_json/\"+i,\"r\") as f:\n        combine.append(json.load(f))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install deepspeed","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import glob\nimport json\nimport logging\nimport os\nfrom dataclasses import dataclass, field\nfrom functools import partial\nfrom typing import Dict, List, Optional, Union, Literal, Tuple\nfrom types import MethodType\nimport torch\nimport transformers\nfrom accelerate.utils import DistributedType\nfrom deepspeed import zero\nfrom deepspeed.runtime.zero.partition_parameters import ZeroParamStatus\n\nfrom transformers import AutoModel, AutoTokenizer\nfrom transformers.integrations import deepspeed\nfrom transformers import AutoModel, AutoTokenizer\n\nfrom peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"compine[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"out=0\no=1\nfor index,values in data.iterrows(): \n        text=\"USER: <image> \\nanswer with true or false,analysis the two images and determine if they the same or not? ASSISTANT:\"\n        image=Image.open(\"/kaggle/input/false-true-images-for-minicpm/make-true-false-image-db/train/\"+values['merged']).resize((512,512))\n\n        #preproces = tokenizer(text=text, images=image ,return_tensors=\"pt\")\n        with torch.inference_mode():\n            inputs=tokenizer(text=text, images=image, return_tensors=\"pt\")\n            generate_ids = model.generate(**inputs, max_new_tokens=15)\n            print(tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0],values['labels'])\nprint(out/len(data))\nimage\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-06-20T17:56:17.402358Z","iopub.execute_input":"2024-06-20T17:56:17.403207Z","iopub.status.idle":"2024-06-20T17:57:00.277231Z","shell.execute_reply.started":"2024-06-20T17:56:17.403170Z","shell.execute_reply":"2024-06-20T17:57:00.275951Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":49,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1659: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"USER:   \nanswer with true or false,analysis the two images and determine if they the same or not? ASSISTANT: The two images are not the same. The first image shows a black and False\nUSER:   \nanswer with true or false,analysis the two images and determine if they the same or not? ASSISTANT: The two images are not the same. The first image shows a triangle with False\nUSER:   \nanswer with true or false,analysis the two images and determine if they the same or not? ASSISTANT: The two images are not the same. The first image is a diagram of True\nUSER:   \nanswer with true or false,analysis the two images and determine if they the same or not? ASSISTANT: The two images are not the same. The first image is a graph with True\nUSER:   \nanswer with true or false,analysis the two images and determine if they the same or not? ASSISTANT: The two images are not the same. The first image features a square with True\nUSER:   \nanswer with true or false,analysis the two images and determine if they the same or not? ASSISTANT: True True\nUSER:   \nanswer with true or false,analysis the two images and determine if they the same or not? ASSISTANT: The two images are not the same. The first image is a graph with False\nUSER:   \nanswer with true or false,analysis the two images and determine if they the same or not? ASSISTANT: The two images are not the same. The first image is a flowchart False\nUSER:   \nanswer with true or false,analysis the two images and determine if they the same or not? ASSISTANT: The two images are not the same. The first image is a black and False\nUSER:   \nanswer with true or false,analysis the two images and determine if they the same or not? ASSISTANT: The two images are not the same. The first image is a circle with False\nUSER:   \nanswer with true or false,analysis the two images and determine if they the same or not? ASSISTANT: True. False\nUSER:   \nanswer with true or false,analysis the two images and determine if they the same or not? ASSISTANT: The two images are not the same. The first image shows a circle with False\nUSER:   \nanswer with true or false,analysis the two images and determine if they the same or not? ASSISTANT: True True\nUSER:   \nanswer with true or false,analysis the two images and determine if they the same or not? ASSISTANT: The two images are not the same. The first image shows a square with True\nUSER:   \nanswer with true or false,analysis the two images and determine if they the same or not? ASSISTANT: The two images are not the same. The first image is a black and False\nUSER:   \nanswer with true or false,analysis the two images and determine if they the same or not? ASSISTANT: The two images are not the same. The first image is a diagram with True\nUSER:   \nanswer with true or false,analysis the two images and determine if they the same or not? ASSISTANT: The two images are not the same. The first image shows a triangle with False\nUSER:   \nanswer with true or false,analysis the two images and determine if they the same or not? ASSISTANT: The two images are not the same. The first image is a whiteboard False\n","output_type":"stream"},{"name":"stderr","text":"\nKeyboardInterrupt\n\n","output_type":"stream"}]},{"cell_type":"code","source":"\n!pip install wandb\nimport wandb\nwandb.login(key=\"14459c516497ab76a78f7fc1278bfe60d301d250\")","metadata":{"papermill":{"duration":14.026469,"end_time":"2023-10-28T13:44:38.629031","exception":false,"start_time":"2023-10-28T13:44:24.602562","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-20T17:57:10.343238Z","iopub.execute_input":"2024-06-20T17:57:10.343668Z","iopub.status.idle":"2024-06-20T17:57:27.954286Z","shell.execute_reply.started":"2024-06-20T17:57:10.343636Z","shell.execute_reply":"2024-06-20T17:57:27.953155Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.17.0)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.41)\nRequirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb) (3.11.0)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.3.1)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (69.0.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"#peftmodel.enable_input_require_grads()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_arguments = TrainingArguments(\n    output_dir=output_dir,\n    num_train_epochs=num_train_epochs,\n    per_device_train_batch_size=1,\n    gradient_accumulation_steps=4,\n    optim=optim,\n    save_steps=40,\n    logging_steps=15,\n    learning_rate=learning_rate,\n    weight_decay=weight_decay,\n    fp16=fp16, \n    bf16=bf16,\n    max_grad_norm=max_grad_norm,\n    max_steps=max_steps,\n    warmup_ratio=warmup_ratio,\n    group_by_length=False,\n    lr_scheduler_type=lr_scheduler_type,\n   gradient_checkpointing=gradient_checkpointing\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-20T17:57:27.956337Z","iopub.execute_input":"2024-06-20T17:57:27.957065Z","iopub.status.idle":"2024-06-20T17:57:27.991047Z","shell.execute_reply.started":"2024-06-20T17:57:27.957029Z","shell.execute_reply":"2024-06-20T17:57:27.989920Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"training_arguments = TrainingArguments(\n    output_dir=output_dir,\n    num_train_epochs=num_train_epochs,\n    per_device_train_batch_size=4,\n    gradient_accumulation_steps=4,\n    optim=optim,\n    save_steps=40,\n    logging_steps=15,\n    learning_rate=learning_rate,\n    weight_decay=weight_decay,\n    fp16=fp16, \n    bf16=bf16,\n    max_grad_norm=max_grad_norm,\n    max_steps=max_steps,\n    warmup_ratio=warmup_ratio,\n    group_by_length=False,\n    lr_scheduler_type=lr_scheduler_type,\n   gradient_checkpointing=gradient_checkpointing\n)\n\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=train_dataset,\n      max_seq_length=18,\n    peft_config=peft_config,\n    dataset_text_field=\"text\",\n    args=training_arguments,\n    packing=False\n)\ntrainer.train()\ntrainer.model.save_pretrained(new_model)","metadata":{"id":"yqq_9dT1_nn7","papermill":{"duration":8.04449,"end_time":"2023-10-28T13:44:46.754051","exception":false,"start_time":"2023-10-28T13:44:38.709561","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-06-20T18:01:32.976904Z","iopub.execute_input":"2024-06-20T18:01:32.977998Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length, dataset_text_field. Will not be supported from version '1.0.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1965: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of ðŸ¤— Transformers. Use `--hub_token` instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1965: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of ðŸ¤— Transformers. Use `--hub_token` instead.\n  warnings.warn(\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:269: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:307: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:397: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n  warnings.warn(\n/tmp/ipykernel_270/4032305884.py:16: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  preproces = tokenizer(text=text+str(d[-1]), images=image, return_tensors=\"pt\",truncation=True,)\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='4' max='87' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 4/87 02:03 < 1:25:05, 0.02 it/s, Epoch 0.03/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"code","source":"trainer.evaluate()\n","metadata":{"papermill":{"duration":699.247728,"end_time":"2023-10-28T19:40:46.786544","exception":false,"start_time":"2023-10-28T19:29:07.538816","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install evaluate","metadata":{"papermill":{"duration":12.363574,"end_time":"2023-10-28T19:40:59.174346","exception":false,"start_time":"2023-10-28T19:40:46.810772","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]}]}